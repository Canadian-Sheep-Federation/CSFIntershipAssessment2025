{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0979be9-2920-4147-8aab-1ab6829d2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrot Detection Pipeline – CSF Internship Assessment\n",
    "\n",
    "#**Autor:** Stephanny Gabriela Sanchez Bautista \n",
    "#**Fecha:** 8/06/2025  \n",
    "#**Objetivo:** Simulate a video processing pipeline using a folder of images to detect carrots. \n",
    "            #Additionally, demonstrate understanding of classification through a simple ML demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0def7a4-b0c3-498c-a919-dadd4d61292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As an AI Development Intern at the CSF, you will be tasked with developing pipelines.\n",
    "#Please answer the following questions in a jupyter notebook. \n",
    "#You should only spend about two hours on these questions. If you want to spend more you can. \n",
    "#If you've run out of time, please describe thoroughly what remains to be done and how you would accomplish it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65601b61-97f0-464c-ba68-53a3cf5f0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Processing Video Pipeline\n",
    "#Assume you have a working ML model that can process individual images and identify carrots, \n",
    "#how would you adapt that model such that you could feed it live video inside a grocery store\n",
    "#and have it create a record of any carrots it sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3623c5-ab41-4365-ace3-945ced9ec828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 1:\n",
    "#If I want to adapt a carrot detection model to process a real-time video from a supermarket:\n",
    "#We trained a roboflow model with Yolv5 in Roboflow platform to detect carrots and we will use the api key with 170 images of carrots\n",
    "#The first step is to extract each frame from the video as an image, I would used 1 second dataframes. \n",
    "#The second step is to pass each frame through the detection model to determine whether a carrot appears in that specific image. \n",
    "#Third, whenever the model detects a carrot, it will extract the position within the frame, the exact timestamp, and the confidence score indicating how likely it is to be a carrot.{\n",
    "#This information should be saved in a .csv file. The entire process will run in continuous cycles, allowing real-time visualization of detected carrots as customers move around the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083259d-62e6-48ac-a5dd-4605ac37a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demo: \n",
    "#Write a toy implementation of whatever machine learning concept you would like in order to demonstrate your skills.\n",
    "#The problems we work on are wholly related to classfication, so your toy implementation should show knowledge of the fundamentals of classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab4d5f-bf21-4841-9993-951dd3520075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies and download Yolov5\n",
    "#Execute this only one time\n",
    "#We are using Yolov5 trained in the Roboflow platform\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a24e16-8c77-4c90-b2ab-b9ee4acdb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We instaled the Roboflow library and \n",
    "# Install Roboflow library\n",
    "!pip install roboflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3acbf273-3c77-436e-a79c-8fe24d3c634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 12 frames saved to 'video_frames_1fps'\n"
     ]
    }
   ],
   "source": [
    "#Upload the video in the main\n",
    "#This code extract one frame every second from the video\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "video_path = \"stephy_carrot_2.mp4\"  # Path to your video\n",
    "output_folder = \"video_frames_1fps\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_id = 0\n",
    "saved = 0\n",
    "frame_info = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id % int(fps) == 0:\n",
    "        timestamp = str(timedelta(seconds=frame_id / fps))\n",
    "        filename = f\"frame_{frame_id:05d}.jpg\"\n",
    "        full_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(full_path, frame)\n",
    "\n",
    "        frame_info.append({\n",
    "            \"frame_id\": frame_id,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"filename\": filename,\n",
    "            \"path\": full_path\n",
    "        })\n",
    "        saved += 1\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"✅ {saved} frames saved to '{output_folder}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818482e0-15a8-492a-b96f-b02be086af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classification complete.\n"
     ]
    }
   ],
   "source": [
    "#Test every frame from the video with the Roboflow model\n",
    "#The API_KEY that I have used is XW0aGMAI2SwH3ZRPEdt2\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"XW0aGMAI2SwH3ZRPEdt2\"  # Replace with your actual Roboflow key in the line 2\n",
    "MODEL_ID = \"carrot-dt8zs-5efjd\"\n",
    "VERSION = 1\n",
    "\n",
    "classification_log = []\n",
    "\n",
    "for entry in frame_info:\n",
    "    # Get image size to calculate area\n",
    "    img = cv2.imread(entry[\"path\"])\n",
    "    if img is None:\n",
    "        continue\n",
    "    h, w = img.shape[:2]\n",
    "    frame_area = w * h\n",
    "\n",
    "    with open(entry[\"path\"], \"rb\") as f:\n",
    "        response = requests.post(\n",
    "            f\"https://detect.roboflow.com/{MODEL_ID}/{VERSION}?api_key={API_KEY}&confidence=10\",\n",
    "            files={\"file\": f}\n",
    "        )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ Failed: {entry['filename']}\")\n",
    "        continue\n",
    "\n",
    "    result = response.json()\n",
    "    detections = result.get(\"predictions\", [])\n",
    "\n",
    "    # Calculate total area covered by all bounding boxes\n",
    "    total_carrot_area = sum([d[\"width\"] * d[\"height\"] for d in detections])\n",
    "    carrot_ratio = total_carrot_area / frame_area if frame_area > 0 else 0\n",
    "\n",
    "    # Decide prediction based on 50% threshold\n",
    "    prediction = 1 if carrot_ratio >= 0.2 else 0\n",
    "\n",
    "    classification_log.append({\n",
    "        \"frame_id\": entry[\"frame_id\"],\n",
    "        \"timestamp\": entry[\"timestamp\"],\n",
    "        \"filename\": entry[\"filename\"],\n",
    "        \"prediction\": prediction,\n",
    "        \"carrot_ratio\": round(carrot_ratio, 4),\n",
    "        \"confidence\": max([d[\"confidence\"] for d in detections], default=None),\n",
    "        \"bbox_count\": len(detections)\n",
    "    })\n",
    "\n",
    "print(\"✅ Classification complete.\") #You know if the clasification model is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1da9f7a-adfa-4122-95a3-2e2fdf890bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>carrot_ratio</th>\n",
       "      <th>confidence</th>\n",
       "      <th>bbox_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>frame_00000.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.927071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0:00:00.999418</td>\n",
       "      <td>frame_00015.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.949548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0:00:01.998836</td>\n",
       "      <td>frame_00030.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.632271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0:00:02.998254</td>\n",
       "      <td>frame_00045.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0:00:03.997673</td>\n",
       "      <td>frame_00060.jpg</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.848164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>0:00:04.997091</td>\n",
       "      <td>frame_00075.jpg</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>0.846088</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90</td>\n",
       "      <td>0:00:05.996509</td>\n",
       "      <td>frame_00090.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.828610</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105</td>\n",
       "      <td>0:00:06.995927</td>\n",
       "      <td>frame_00105.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0.473713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120</td>\n",
       "      <td>0:00:07.995345</td>\n",
       "      <td>frame_00120.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0.888660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>135</td>\n",
       "      <td>0:00:08.994763</td>\n",
       "      <td>frame_00135.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.748456</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150</td>\n",
       "      <td>0:00:09.994181</td>\n",
       "      <td>frame_00150.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.768583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>165</td>\n",
       "      <td>0:00:10.993599</td>\n",
       "      <td>frame_00165.jpg</td>\n",
       "      <td>Not-Carrot</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.651912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_id       timestamp         filename  prediction  carrot_ratio  \\\n",
       "0          0         0:00:00  frame_00000.jpg  Not-Carrot        0.1064   \n",
       "1         15  0:00:00.999418  frame_00015.jpg  Not-Carrot        0.0952   \n",
       "2         30  0:00:01.998836  frame_00030.jpg  Not-Carrot        0.0612   \n",
       "3         45  0:00:02.998254  frame_00045.jpg  Not-Carrot        0.1842   \n",
       "4         60  0:00:03.997673  frame_00060.jpg      Carrot        0.3501   \n",
       "5         75  0:00:04.997091  frame_00075.jpg      Carrot        0.3805   \n",
       "6         90  0:00:05.996509  frame_00090.jpg  Not-Carrot        0.1139   \n",
       "7        105  0:00:06.995927  frame_00105.jpg  Not-Carrot        0.1198   \n",
       "8        120  0:00:07.995345  frame_00120.jpg  Not-Carrot        0.0896   \n",
       "9        135  0:00:08.994763  frame_00135.jpg  Not-Carrot        0.0799   \n",
       "10       150  0:00:09.994181  frame_00150.jpg  Not-Carrot        0.1440   \n",
       "11       165  0:00:10.993599  frame_00165.jpg  Not-Carrot        0.0701   \n",
       "\n",
       "    confidence  bbox_count  \n",
       "0     0.927071           1  \n",
       "1     0.949548           1  \n",
       "2     0.632271           1  \n",
       "3     0.738772           2  \n",
       "4     0.848164           3  \n",
       "5     0.846088           3  \n",
       "6     0.828610           2  \n",
       "7     0.473713           1  \n",
       "8     0.888660           2  \n",
       "9     0.748456           2  \n",
       "10    0.768583           1  \n",
       "11    0.651912           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the predictions on a .ccv field\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(classification_log)\n",
    "df.to_csv(\"carrot_area_based_classification.csv\", index=False)\n",
    "\n",
    "# Load and label\n",
    "df[\"prediction\"] = df[\"prediction\"].map({1: \"Carrot\", 0: \"Not-Carrot\"})\n",
    "\n",
    "# Show all results\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df\n",
    "\n",
    "#The carrot_ratio determines if the carrot is in the frame and prediction determines if carrot_ratio is more than 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92280d7-7951-4daa-a051-7ce1f9b4e5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
