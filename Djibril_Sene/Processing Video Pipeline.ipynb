{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e10d90",
   "metadata": {},
   "source": [
    "Assume you have a working ML model that can process individual images and identify carrots, how would you adapt that model such that you could feed it live video inside a grocery store and have it create a record of any carrots it sees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76cb7b",
   "metadata": {},
   "source": [
    "My approach to this problem would be as follows:\n",
    "\n",
    "- First, I would capture the live video stream using a tool such as OpenCV, which provides frame-by-frame access in real time. This serves as the foundation for integrating video input into the classification pipeline.\n",
    "\n",
    "- Since processing every frame is both unnecessary and computationally expensive, I would sample the video at a fixed rate such as one frame per second or every Nth frame. Given that carrots are unlikely to move quickly or exit the frame within a second in a grocery store setting, this sampling rate should be sufficient to detect them reliably while reducing system load.\n",
    "\n",
    "- Each sampled frame would then be preprocessed to match the model's input requirements (e.g., resizing, normalization, and color space adjustments), ensuring consistency between training and inference conditions.\n",
    "\n",
    "- The preprocessed frames would be passed to the classification model, which would determine the presence or absence of carrots in each frame.\n",
    "\n",
    "- Once a carrot is detected in a frame, the system would log the sighting in a structured format. Relevant frames would be stored in a dedicated image directory or database. Alongside this, a separate metadata store (e.g., SQL or JSON) would maintain information such as the frame ID, a unique carrot ID, detection timestamps (first and most recent), model confidence score, and if available; bounding box coordinates or object positions. This combination of visual and metadata records would enable efficient querying, analysis, and reconstruction of each carrot’s trajectory within the camera’s field of view.\n",
    "\n",
    "- A major challenge lies in avoiding duplicate entries when the same carrot appears in multiple frames. To address this, I would implement a lightweight object tracking mechanism to assign consistent IDs to carrots across time. If the model supports object detection (e.g., with bounding boxes), tracking can be performed both spatially and temporally(we could use the camera timestamp for this dimension). For more robust tracking, algorithms like SORT or DeepSORT could be integrated. These algorithms combine motion cues and appearance features to maintain object identity, allowing the system to update an existing carrot log rather than duplicating entries. This results in more accurate temporal and behavioral records for each unique carrot, even as it moves through the scene.\n",
    "\n",
    "While this approach is robust, it does come with certain limitations. Inference speed may become a bottleneck, particularly if the model is large or the system is running on constrained hardware. Furthermore, if the underlying model is a pure image classifier (rather than an object detector), it will only indicate the presence of a carrot in the frame, without providing localization. This makes tracking and distinguishing between multiple carrots more difficult. In scenarios where multiple similar looking carrots are close together, the system may erroneously merge them into a single detection. Finally, storing full images or cropped detections for each carrot can quickly consume storage space, especially in long-duration videos or high-traffic scenes. To mitigate this, optimizations such as saving only the first appearance, compressing images, or storing only feature vectors can be considered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
