{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Class Carrot Detection in Webcam Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses a pre-trained MobileNetV2 model to extract features from images. These features then train a One-Class SVM to identify carrots. The system captures live webcam frames, extracts features from each, and uses the SVM to detect carrots. Detected carrots are logged with a timestamp, and results are displayed live on the frame. Finally, all detections in the video (only 100 frames due to size limits) are saved to a CSV file.\n",
    "\n",
    "Potential Future Improvements\n",
    "- Add object detection for bounding boxes: To pinpoint where carrots are, not just if they're present.\n",
    "- Implement tracking to count unique carrots: To avoid counting the same carrot multiple times across frames.\n",
    "- Use a binary classifier (carrot vs. non-carrot) and robustly trained for better performance: A one-class model can struggle with diverse \"not carrot\" examples. \n",
    "- Optimize for real-time performance (e.g., GPU, quantization): To ensure smooth, high-speed processing for live video.\n",
    "- Handle multiple carrots in one frame: The current system only indicates presence, not quantity of items at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.13.4' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load pretrained feature extractor\n",
    "model = models.mobilenet_v2(pretrained=True).features\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def extract_feature(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        feature = model(img_tensor).squeeze().mean([1, 2]).numpy()  # Global avg pooling\n",
    "    return feature\n",
    "\n",
    "# Folder of carrot images\n",
    "features = []\n",
    "for file in os.listdir(\"../fruits-360/Training/Carrot 1\"):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "        f = extract_feature(os.path.join(\"../fruits-360/Training/Carrot 1\", file))\n",
    "        features.append(f)\n",
    "\n",
    "X = np.vstack(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "clf = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Setup logging\n",
    "carrot_log = []\n",
    "\n",
    "# Show image in notebook\n",
    "def show_frame(frame):\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    clear_output(wait=True)\n",
    "    display(img)\n",
    "\n",
    "# Carrot detection + logging\n",
    "def is_carrot(frame):\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    tensor = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        feature = model(tensor).squeeze().mean([1, 2]).numpy()\n",
    "    is_detected = clf.predict([feature])[0] == 1\n",
    "\n",
    "    if is_detected:\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        carrot_log.append((timestamp, \"Carrot detected\"))\n",
    "\n",
    "    return is_detected\n",
    "\n",
    "# Start camera loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "for _ in range(100):  # or use while True for continuous\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    label = \"Carrot\" if is_carrot(frame) else \"Not Carrot\"\n",
    "    cv2.putText(frame, label, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    show_frame(frame)\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save log to CSV\n",
    "import csv\n",
    "with open(\"carrot_log.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"timestamp\", \"event\"])\n",
    "    writer.writerows(carrot_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
